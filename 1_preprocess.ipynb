{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input Spectrum Data Preprocessing\n",
    "- Create an output parameter dataset with `obsid` as the key, in preparation for merging with the input spectrum dataset.\n",
    "\n",
    "- Create an input spectrum dataset, also with `obsid` as the key.\n",
    "  - LAMOST official website, \"It is worth noting that the wavelength range of the flattened spectrum is [3800 Å, 8900 Å]\"\n",
    "\n",
    "- The flux of the flattened spectrum is incorporated into the atmospheric parameter dataset to form the training dataset `LAMOST_Gaia_APOGEE_param.csv`\n",
    "  - The `flag` field in the file indicates whether there are flux points that have been simply set to zero (possibly bad spectra).\n",
    "\n",
    "\n",
    "#### 输入光谱数据预处理\n",
    "- 制作输出参数数据集，以obsid为键，为与输入光谱数据集拼接做准备\n",
    "- 制作输入光谱数据集，同样以obsid为键\n",
    "  - LAMOST官网！\"值得注意的是：拉平光谱的波长范围是[3800 Å, 8900 Å]\"\n",
    "\n",
    "- 拉平后的光谱流量并入大气参数数据集共同构成训练数据集 `LAMOST_Gaia_APOGEE_param.csv`\n",
    "  - 文件中 `flag` 字段表示是否存在流量点被简单置零(可能为坏光谱)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter\n",
    "import os\n",
    "plt.style.use('default')\n",
    "\n",
    "# spectra file path\n",
    "LAMOST_Gaia_APOGEE_specdir_path = 'data/spec_dir/'\n",
    "LAMOST_Gaia_APOGEE_path = 'data/LAMOST_Gaia_APOGEE.csv'\n",
    "# output path\n",
    "LAMOST_Gaia_APOGEE_parampath = 'data/LAMOST_Gaia_APOGEE_param.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a continuous spectrum to the red and blue parts respectively    \n",
    "# find strong lines\n",
    "def find_strong_line(wave, flux):\n",
    "    coeff = np.polyfit(wave, flux, 5)\n",
    "    formula = np.poly1d(coeff)\n",
    "    y = formula(wave)\n",
    "    d = y - flux\n",
    "    sigma = np.std(d)\n",
    "    n = np.where((flux < y - 3 * sigma) | (flux > y + 3 * sigma))\n",
    "    a = n[0]\n",
    "    i = 0\n",
    "    left = []\n",
    "    right = []\n",
    "    while i < len(a):\n",
    "        head = i\n",
    "        length = 0\n",
    "        while (i < len(a) - 1) and (a[i + 1] == a[i] + 1):\n",
    "            length += 1\n",
    "            i += 1\n",
    "        if head == 0:\n",
    "            left.append(np.max([a[head] - length, 0]))\n",
    "        else:\n",
    "            left.append(np.max([a[head] - length, a[head - 1] + 1]))\n",
    "\n",
    "        if i == len(a) - 1:\n",
    "            right.append(np.min([a[i] + length, len(wave) - 1]))\n",
    "        else:\n",
    "            right.append(np.min([a[i] + length, a[i + 1] - 1]))\n",
    "        i += 1\n",
    "    return wave[left], wave[right]\n",
    "\n",
    "# mask strong lines\n",
    "def mask_strong_line(wave, flux, left, right):\n",
    "    for i in range(len(left)):\n",
    "        n = np.where((wave < left[i]) | (wave > right[i]))\n",
    "        wave = wave[n]\n",
    "        flux = flux[n]\n",
    "    return [wave, flux]\n",
    "\n",
    "def find_conti_spec(wave, flux, nploy):\n",
    "    for i in np.arange(10):\n",
    "        coeff = np.polyfit(wave, flux, nploy)\n",
    "        formula = np.poly1d(coeff)\n",
    "        y = formula(wave)\n",
    "        d = y - flux\n",
    "        sigma = np.std(d)\n",
    "        n = np.where(d < sigma)\n",
    "        wave = wave[n]\n",
    "        flux = flux[n]\n",
    "    return formula\n",
    "\n",
    "def normalize_blue_spec(wave, flux):\n",
    "    left, right = find_strong_line(wave, flux)\n",
    "    wave1, flux1 = mask_strong_line(wave, flux, left, right)\n",
    "    formula = find_conti_spec(wave1, flux1, 5)\n",
    "    conti = formula(wave)\n",
    "    return flux / conti\n",
    "\n",
    "def normalize_red_spec(wave, flux):\n",
    "    left, right = find_strong_line(wave, flux)\n",
    "    wave1, flux1 = mask_strong_line(wave, flux, left, right)\n",
    "    formula = find_conti_spec(wave1, flux1, 5)\n",
    "    conti = formula(wave)\n",
    "    return flux / conti\n",
    "\n",
    "def get_fileNameList(file_dir):\n",
    "    # `root` is the current directory path, \n",
    "    # `dirs` are all subdirectories in the current path, \n",
    "    # `files` are all non-directory files in the current path.\n",
    "    # root当前目录路径, dirs当前路径下所有子目录, files当前路径下所有非目录子文件\n",
    "    for root, dirs, files in os.walk(file_dir): \n",
    "        fileNameList = files\n",
    "    return fileNameList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": "LAMOST_Gaia_APOGEE = pd.read_csv(LAMOST_Gaia_APOGEE_path)"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an output parameter dataset using `obsid` as the key, in preparation for merging with the input spectrum dataset.\n",
    "# 制作输出参数数据集，以obsid为键，为与输入光谱数据集拼接做准备\n",
    "id = ['obsid']\n",
    "LAMOST_Gaia_APOGEE_labels = ['TEFF_1','LOGG_1','FE_H','mg_geo','bp_rp_0']\n",
    "\n",
    "LAMOST_Gaia_APOGEE_param =  LAMOST_Gaia_APOGEE.loc[:,id+LAMOST_Gaia_APOGEE_labels]\n",
    "LAMOST_Gaia_APOGEE_param.rename(columns = {'TEFF_1':'teff','LOGG_1':'logg','FE_H':'feh'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": "LAMOST_Gaia_APOGEE_spec_namelist = get_fileNameList(LAMOST_Gaia_APOGEE_specdir_path)"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n"
     ]
    }
   ],
   "source": [
    "fileList = LAMOST_Gaia_APOGEE_spec_namelist\n",
    "filedir = LAMOST_Gaia_APOGEE_specdir_path\n",
    "\n",
    "flux = []\n",
    "obsid = []\n",
    "flag = [] # flag=1 表示有超出阈值的流量点被置1, flag=0 则没有\n",
    "wave = np.arange(3925,8800,1)\n",
    "j = 0\n",
    "\n",
    "for file in fileList:\n",
    "    try:\n",
    "        file_path = filedir + file\n",
    "        hdu = fits.open(file_path,memmap=False)\n",
    "        id = hdu[0].header['obsid']\n",
    "        z = hdu[0].header['z']\n",
    "        bad_pix = np.append(np.nonzero(hdu[1].data[0][3]),np.nonzero(hdu[1].data[0][4]))\n",
    "        f = np.delete(hdu[1].data[0][0],bad_pix) # 去除坏像素，与标识位&或标识位\n",
    "        w = np.delete(hdu[1].data[0][2],bad_pix)\n",
    "        w = w / (1 + z) # rest wave\n",
    "        # !!!\n",
    "        f_smooth = savgol_filter(f, 15, 7)\n",
    "        # 分红蓝端去除连续谱\n",
    "        index_b = np.where(w < 6000)\n",
    "        index_r = np.where(w >= 6000)\n",
    "        w_r = w[index_r]\n",
    "        w_b = w[index_b]\n",
    "        f_smooth_b = f_smooth[index_b]\n",
    "        f_smooth_r = f_smooth[index_r]\n",
    "\n",
    "        warnings.simplefilter('ignore', np.RankWarning)\n",
    "\n",
    "        norm_b_smooth = normalize_blue_spec(w_b,f_smooth_b)\n",
    "        norm_r_smooth = normalize_red_spec(w_r,f_smooth_r)\n",
    "        norm_smooth = np.append(norm_b_smooth,norm_r_smooth)\n",
    "\n",
    "        # 拟合\n",
    "        f_inter_smooth = interp1d(w,norm_smooth)\n",
    "        # 自己写的拉平函数的流量 插值统一波长范围\n",
    "        f_normed_smooth = f_inter_smooth(wave)\n",
    "\n",
    "        # !!!\n",
    "        f_check = np.array(f_normed_smooth)\n",
    "        cond = np.where((f_check > 1.2) | (f_check < 0.1))[0]\n",
    "\n",
    "        if len(cond) == 0:\n",
    "            flux.append(f_normed_smooth)\n",
    "            flag.append(0)\n",
    "        elif len(cond) != 0:\n",
    "            f_check[cond] = 1\n",
    "            flux.append(f_check)\n",
    "            flag.append(1)\n",
    "            \n",
    "        obsid.append(id)\n",
    "        hdu.close()\n",
    "\n",
    "        j = j + 1\n",
    "        if j % 1000 == 0:\n",
    "            print(j)\n",
    "\n",
    "    # Spectra wavelengths not within the required range\n",
    "    except Exception as e:\n",
    "        if file.endswith('.fits'):\n",
    "            print('An exception occurred. Error File: ' + file)\n",
    "            print('wavelength: ','[',w[0],',',w[len(w)-1],']')\n",
    "            print(j)\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag=1 indicates that there are flux points exceeding the threshold that have been set to 1, otherwise flag=0\n",
    "firstline = ['obsid','flag'] + [str(i) for i in list(np.arange(3925,8800,1))]\n",
    "obsid_pd = pd.DataFrame(obsid)\n",
    "flag_pd = pd.DataFrame(flag)\n",
    "flux_pd = pd.DataFrame(flux)\n",
    "all = pd.concat([obsid_pd,flag_pd,flux_pd],axis=1)\n",
    "all.columns=firstline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save flux into the LAMOST_Gaia_param table (using obsid as the key)\n",
    "LAMOST_Gaia_APOGEE_paramall = LAMOST_Gaia_APOGEE_param.merge(all,how='left',on='obsid')\n",
    "LAMOST_Gaia_APOGEE_paramall.to_csv(LAMOST_Gaia_APOGEE_parampath,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "443d3b7b06c193880b8077a6d7f00bbf36b63f464cba17b8ff6539aed0d729fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
